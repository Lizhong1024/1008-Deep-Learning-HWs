{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw5_problem5_adapter_fusion.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HywR0S12rPDX"},"source":["## Problem 5"]},{"cell_type":"code","metadata":{"id":"KC9WZDt3xkPM"},"source":["## For this question, fill in the TODO's "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmqCEJrUbi0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606928835978,"user_tz":300,"elapsed":17181,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"54c5f09b-94c7-48bd-fbce-e8c23a5a1730"},"source":["!pip install git+https://github.com/adapter-hub/adapter-transformers.git\n","!git clone https://github.com/huggingface/transformers\n","!python transformers/utils/download_glue_data.py --tasks RTE\n","\n","import dataclasses\n","import logging\n","import os\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","\n","import numpy as np\n","\n","import torch\n","from transformers import AutoTokenizer, EvalPrediction, GlueDataset, GlueDataTrainingArguments, AutoModelWithHeads, AdapterType, AutoConfig, AutoModelForSequenceClassification\n","from transformers import GlueDataTrainingArguments as DataTrainingArguments\n","from transformers import (\n","    Trainer,\n","    TrainingArguments,\n","    glue_compute_metrics,\n","    glue_tasks_num_labels,\n","    set_seed,\n",")\n","\n","model_name = 'bert-base-uncased'\n","\n","\n","# Refer to the notebook for training an adapter to write these. Set the number of epochs to 3, and learning rate to 5e-5. Rest of the hyperparameters can stay the same. \n","\n","data_args = GlueDataTrainingArguments(task_name=\"rte\", data_dir=\"./glue_data/RTE\")\n","\n","training_args = TrainingArguments(\n","    logging_steps=50,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=64,\n","    save_steps=1000,\n","    evaluation_strategy='steps',\n","    output_dir='./models/rte',\n","    overwrite_output_dir=True,\n","    do_train=True,\n","    do_eval=True,\n","    learning_rate=5e-5,\n","    num_train_epochs=3,\n",")\n","\n","# TODO: Change this seed when re-running your code to report the mean and std dev\n","#set_seed(2020)\n","#set_seed(666)\n","set_seed(1024)\n","num_labels = glue_tasks_num_labels[data_args.task_name]\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/adapter-hub/adapter-transformers.git\n","  Cloning https://github.com/adapter-hub/adapter-transformers.git to /tmp/pip-req-build-nyf7a393\n","  Running command git clone -q https://github.com/adapter-hub/adapter-transformers.git /tmp/pip-req-build-nyf7a393\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied (use --upgrade to upgrade): adapter-transformers==1.1.0 from git+https://github.com/adapter-hub/adapter-transformers.git in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (0.0.43)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (20.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (2019.12.20)\n","Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (0.1.91)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (3.12.4)\n","Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (0.9.3)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (0.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adapter-transformers==1.1.0) (1.18.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->adapter-transformers==1.1.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->adapter-transformers==1.1.0) (0.17.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->adapter-transformers==1.1.0) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->adapter-transformers==1.1.0) (2.4.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->adapter-transformers==1.1.0) (50.3.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->adapter-transformers==1.1.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->adapter-transformers==1.1.0) (2020.11.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->adapter-transformers==1.1.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->adapter-transformers==1.1.0) (1.24.3)\n","Building wheels for collected packages: adapter-transformers\n","  Building wheel for adapter-transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adapter-transformers: filename=adapter_transformers-1.1.0-cp36-none-any.whl size=1325191 sha256=6dcc5d87a50a188bd9521fe52d4401f2dfb047816ad57d142df2691194651bda\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-i3vmfd4e/wheels/22/eb/df/1c86c6a1b0323a74470d6a53db05b3b49ec79bce18d253ec38\n","Successfully built adapter-transformers\n","fatal: destination path 'transformers' already exists and is not an empty directory.\n","Downloading and extracting RTE...\n","\tCompleted!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3JRwqK_-TbPU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606928839570,"user_tz":300,"elapsed":17354,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"2bff2bf7-57e8-4823-c446-478fedd14972"},"source":["config = AutoConfig.from_pretrained(\n","        model_name,\n","        num_labels=num_labels,\n","        finetuning_task=data_args.task_name,\n","        cache_dir=\".\",\n","    )\n","\n","tokenizer = AutoTokenizer.from_pretrained(\n","    model_name,\n","    cache_dir=\".\",\n",")\n","\n","model = AutoModelWithHeads.from_pretrained(model_name, config=config)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"QxY1ayPk340s"},"source":["Now we have everything set up to load our AdapterFusion setup. \n","\n","First, you need to go to adapterhub.ml and explore the different adapters available. Choose any three adapters and load the three adapters. As we don't need their prediction heads, we pass with_head=False to the loading method. Next, we add a new fusion layer that combines all the adapters we've just loaded. Finally, we add a new classification head for our target task on top."]},{"cell_type":"code","metadata":{"id":"rxE-ebUo37jm"},"source":["# First, load the pre-trained adapters we want to fuse from Hub\n","from transformers.adapter_config import PfeifferConfig\n","\n","model.load_adapter(\"nli/rte@ukp\", \"text_task\", config=PfeifferConfig(), load_as='rte', with_head=False)\n","# TODO: load some more adapters. Choose the ones that you think will help RTE task after reading about the different tasks available and how big the datasets are.\n","model.load_adapter('sts/mrpc@ukp', config=PfeifferConfig(), load_as='mrpc', with_head=False)\n","model.load_adapter(\"nli/multinli@ukp\", \"text_task\", config=PfeifferConfig(), load_as='mnli', with_head=False)\n","model.load_adapter(\"nli/sick@ukp\", \"text_task\", config=PfeifferConfig(), load_as='sick', with_head=False)\n","\n","\n","\n","# Add a fusion layer and tell the model to train fusion (freezes the rest of the weights) (here can either add the actual atsk adapter or not)\n","model.add_fusion([\n","        \"rte\",\n","        # TODO: Add your other task names here for the adapters you chose\n","        'mrpc',\n","        'mnli',\n","        'sick'\n","    ])\n","\n","# Add a classification head for our target task\n","# TODO: Check the earlier notebook from Problem 5 to see how to add a classification head for your task.\n","model.add_classification_head('rte', num_labels=num_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1G4aQBqn3pkl"},"source":["The last preparation step is to define and activate our adapter setup. Similar to train_adapter(), train_fusion() does two things: It freezes all weights of the model (including adapters!) except for the fusion layer and classification head. It also activates the given adapter setup to be used in very forward pass.\n","\n","The syntax for the adapter setup (which is also applied to other methods such as set_active_adapters()) works as follows:\n","\n","a single string is interpreted as a single adapter, \n","a list of strings is interpreted as a stack of adapters,\n","a nested list of strings is interpreted as a fusion of adapters. Here want to do Fusion so we use a nested list as follows. \n"]},{"cell_type":"code","metadata":{"id":"aLgNXXBi3sE7"},"source":["# QUESTION: What's the difference between a stack of adapters and a fusion of adapters?\n","\n","adapter_setup = [\n","                 [\n","        \"rte\",\n","        # TODO: Add your other adapter names here. \n","        'mrpc',\n","        'mnli',\n","        'sick'\n","    ]\n","]\n","model.train_fusion(adapter_setup)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FS-UUxG3u2zN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606928841384,"user_tz":300,"elapsed":15454,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"30538882-6e35-46e3-9015-6080f333cabf"},"source":["# Check out your training args\n","print(training_args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TrainingArguments(output_dir='./models/rte', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=64, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec02_17-07-14_8d8ba28de9c3', logging_first_step=False, logging_steps=50, save_steps=1000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=50, dataloader_num_workers=0, past_index=-1, run_name='./models/rte', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RbZqYAVZTyFn"},"source":["###### seed=2020"]},{"cell_type":"code","metadata":{"id":"l128JFN3Vr9n","colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"status":"ok","timestamp":1606926648624,"user_tz":300,"elapsed":164332,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"9bbcfd9c-9785-4783-b8a4-3457941aebc7"},"source":["train_dataset = GlueDataset(data_args, tokenizer=tokenizer)\n","eval_dataset = GlueDataset(data_args, tokenizer=tokenizer, mode=\"dev\")\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","        do_save_full_model=False,\n","        do_save_adapter_fusion=True,\n","    )\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/datasets/glue.py:77: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:521: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [234/234 02:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.412307</td>\n","      <td>0.811673</td>\n","      <td>0.718412</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.210778</td>\n","      <td>0.944624</td>\n","      <td>0.736462</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.162032</td>\n","      <td>1.012837</td>\n","      <td>0.729242</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.154319</td>\n","      <td>1.034165</td>\n","      <td>0.722022</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0, 'eval_acc': 0.7292418772563177, 'eval_loss': 1.0329092741012573}"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"4If88EtoT2qx"},"source":["###### seed=666"]},{"cell_type":"code","metadata":{"id":"jaO2ET8Eu-fE","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"ok","timestamp":1606927166090,"user_tz":300,"elapsed":160743,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"81eb3eb0-cfbd-421e-ad61-196498b854e7"},"source":["train_dataset = GlueDataset(data_args, tokenizer=tokenizer)\n","eval_dataset = GlueDataset(data_args, tokenizer=tokenizer, mode=\"dev\")\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","        do_save_full_model=False,\n","        do_save_adapter_fusion=True,\n","    )\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/datasets/glue.py:77: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:521: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [234/234 02:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.532900</td>\n","      <td>0.562869</td>\n","      <td>0.750903</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.398061</td>\n","      <td>0.669980</td>\n","      <td>0.736462</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.264239</td>\n","      <td>0.833310</td>\n","      <td>0.703971</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.203078</td>\n","      <td>0.945233</td>\n","      <td>0.718412</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0, 'eval_acc': 0.703971119133574, 'eval_loss': 0.9585854411125183}"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"MMIsBPDDT4Ia"},"source":["###### seed=1024"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"9-8p5mVXT54T","executionInfo":{"status":"ok","timestamp":1606928998666,"user_tz":300,"elapsed":157280,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"486073e2-22fe-4ca1-dafe-e56ea4786bab"},"source":["train_dataset = GlueDataset(data_args, tokenizer=tokenizer)\n","eval_dataset = GlueDataset(data_args, tokenizer=tokenizer, mode=\"dev\")\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","        do_save_full_model=False,\n","        do_save_adapter_fusion=True,\n","    )\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/datasets/glue.py:77: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:521: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [234/234 02:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.546966</td>\n","      <td>0.560257</td>\n","      <td>0.736462</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.434188</td>\n","      <td>0.619067</td>\n","      <td>0.725632</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.326838</td>\n","      <td>0.690678</td>\n","      <td>0.725632</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.226932</td>\n","      <td>0.835437</td>\n","      <td>0.722022</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0, 'eval_acc': 0.7220216606498195, 'eval_loss': 0.8418311476707458}"]},"metadata":{"tags":[]},"execution_count":6}]}]}