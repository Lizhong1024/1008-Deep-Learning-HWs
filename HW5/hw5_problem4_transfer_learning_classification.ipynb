{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw5_problem4_transfer_learning_classification.ipynb","provenance":[{"file_id":"1aXtusdQsXNGUwkmtnqFOHH34TinD7j8o","timestamp":1605283048552},{"file_id":"https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb","timestamp":1604973155173}],"collapsed_sections":["8EsG17YWRV5y","niCRjZF3RSOK","0EiWLQ8RRC4V","WJ3hM1UzBJCS","nqxkzC1CBMWq"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3c2c8ee1234f4bdd8f09df75d61a91c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_13e7e71094064ca6870093c651ecd964","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_20453a5cd3ac4c0cbfe6714533170478","IPY_MODEL_d3387364f2ed4664ad01caf47542454d"]}},"13e7e71094064ca6870093c651ecd964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"20453a5cd3ac4c0cbfe6714533170478":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c60064700b3d42fd863288494f2e0886","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_280bfb7384ae4962aed253893c7e3e14"}},"d3387364f2ed4664ad01caf47542454d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1165d56ce12a4d5596ec0f34e15352e6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:07&lt;00:00, 61.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a80e201175840bdb0ba53d741f44a07"}},"c60064700b3d42fd863288494f2e0886":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"280bfb7384ae4962aed253893c7e3e14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1165d56ce12a4d5596ec0f34e15352e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4a80e201175840bdb0ba53d741f44a07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b46c92262729468585d6f565936b90c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f8b1c91509dc4f6a8f70839089a8c0d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bb5c77fbd7d4410ca27786362a72e1a8","IPY_MODEL_4f3a205d1594415ca05ab9aac22b79f7"]}},"f8b1c91509dc4f6a8f70839089a8c0d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb5c77fbd7d4410ca27786362a72e1a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_530e7fff62304fdaa5e3bb800ffbc3ed","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1ef44de9e4147779697d566609778de"}},"4f3a205d1594415ca05ab9aac22b79f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_47aeba9b43d64d5e996a281a5b77eb3d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:01&lt;00:00, 119kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23ec3e7f115f416b9bcc280e4c1cc7ad"}},"530e7fff62304fdaa5e3bb800ffbc3ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f1ef44de9e4147779697d566609778de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47aeba9b43d64d5e996a281a5b77eb3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"23ec3e7f115f416b9bcc280e4c1cc7ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9ac016fa197b4502a70447510d6f901a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ed4b0bc9387e4599ac57d3760a6cff78","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ce0515259bd0435f85b0156ec0f70c10","IPY_MODEL_ee68887bab4b416f8af83c13689d7a10"]}},"ed4b0bc9387e4599ac57d3760a6cff78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce0515259bd0435f85b0156ec0f70c10":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_031eab9705c148f9894f90ff8371ad54","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1396db3318d54f558291d029e33ae1d0"}},"ee68887bab4b416f8af83c13689d7a10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b49fc0bf68f4421096a619e305372b7c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:03&lt;00:00, 120kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cc2944fefb3e483295632a89456637e3"}},"031eab9705c148f9894f90ff8371ad54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1396db3318d54f558291d029e33ae1d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b49fc0bf68f4421096a619e305372b7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cc2944fefb3e483295632a89456637e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"sRRA4H5UaiN5"},"source":["# Problem 4\n","\n","In this problem, we simply finetune a BERT model (not pretrained) on RTE dataset, and then finetune a BERT model (pretrained) on RTE dataset.\n","\n","**IMPORTANT NOTES**:\n","- Please make sure that you have already read the part of hw5 pdf that corresponds to this problem. This is very important.\n","- At the end of the hw5, you will need to submit a zip folder containing three things. The instruction is also included in the first paragraph of the hw5 pdf.\n","  - (1) The writeup pdf containing your solutions to Problems 1, 2, 3, 4, 5. Yes, there're things you need to respond in your writeup (see hw5 pdf).\n","  - (2) The downloaded colab corresponding to Problem 4.\n","  - (3) The downloaded colab corresponding to Problem 5."]},{"cell_type":"markdown","metadata":{"id":"tPcxZxOfGnMO"},"source":["Some imports and data downloading"]},{"cell_type":"code","metadata":{"id":"4prQ5aWt20vn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607054987609,"user_tz":300,"elapsed":19286,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"01b5d1fe-d9c4-435c-bd3a-98ef34aad830"},"source":["!git clone https://github.com/huggingface/transformers\n","!python transformers/utils/download_glue_data.py --tasks RTE\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 53, done.\u001b[K\n","remote: Counting objects: 100% (53/53), done.\u001b[K\n","remote: Compressing objects: 100% (51/51), done.\u001b[K\n","remote: Total 54608 (delta 15), reused 26 (delta 0), pack-reused 54555\u001b[K\n","Receiving objects: 100% (54608/54608), 40.74 MiB | 10.65 MiB/s, done.\n","Resolving deltas: 100% (38155/38155), done.\n","Downloading and extracting RTE...\n","\tCompleted!\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 5.9MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 33.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 37.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=ddae251639a45dc1ef281039c9754b413d596ef8f4942c037bd71315c8e68b42\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CE3DrrKCfDAd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607054987610,"user_tz":300,"elapsed":19278,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"e27341f0-1a52-4e0f-b7f9-07c488e98c6f"},"source":["!ls glue_data/RTE/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dev.tsv  test.tsv  train.tsv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Mll62bB2-g3"},"source":["import dataclasses\n","import logging\n","import os\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn \n","from transformers import AutoTokenizer, EvalPrediction, GlueDataset, GlueDataTrainingArguments, AutoModel, BertPreTrainedModel, AutoConfig, BertModel\n","from transformers import GlueDataTrainingArguments \n","from transformers import (\n","    Trainer,\n","    TrainingArguments,\n","    glue_compute_metrics,\n","    glue_tasks_num_labels,\n","    set_seed,\n",")\n","\n","# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I1TiFjM93SOf"},"source":["model_name = \"bert-base-uncased\"\n","\n","data_args = GlueDataTrainingArguments(task_name=\"rte\", data_dir=\"./glue_data/RTE\")\n","training_args = TrainingArguments(\n","    logging_steps=50, \n","    per_device_train_batch_size=32, \n","    per_device_eval_batch_size=64, \n","    save_steps=1000,\n","    #evaluate_during_training=True,\n","    evaluation_strategy='steps',\n","    output_dir=\"./models/rte\",\n","    overwrite_output_dir=True,\n","    do_train=True,\n","    do_eval=True,\n","    do_predict=True,\n","    learning_rate=0.00001,\n","    num_train_epochs=15,\n",")\n","#set_seed(42)\n","#set_seed(66)\n","set_seed(1024)\n","num_labels = glue_tasks_num_labels[data_args.task_name]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"93lLGbD1G3pE"},"source":["### From non-pretrained BERT"]},{"cell_type":"markdown","metadata":{"id":"2R-0NnqSub6G"},"source":["TODO:\n","- Complete the following three lines such that ```tokenizer``` and ```config``` and ```bert_model``` corresponds to the ```model_name``` we defined in the above cells. \n","- IMPORTANT: make sure that the BERT model does not load pretrained weights!\n","- Hint: https://huggingface.co/transformers/model_doc/auto.html and other relevant Hugging Face documentations. Consider using the tools we imported in the first cell. More hints: it's okay to use ```from_pretrained``` in the first two lines, depending on what class you use."]},{"cell_type":"code","metadata":{"id":"AAIHYGLTsJ-a","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["3c2c8ee1234f4bdd8f09df75d61a91c4","13e7e71094064ca6870093c651ecd964","20453a5cd3ac4c0cbfe6714533170478","d3387364f2ed4664ad01caf47542454d","c60064700b3d42fd863288494f2e0886","280bfb7384ae4962aed253893c7e3e14","1165d56ce12a4d5596ec0f34e15352e6","4a80e201175840bdb0ba53d741f44a07","b46c92262729468585d6f565936b90c6","f8b1c91509dc4f6a8f70839089a8c0d2","bb5c77fbd7d4410ca27786362a72e1a8","4f3a205d1594415ca05ab9aac22b79f7","530e7fff62304fdaa5e3bb800ffbc3ed","f1ef44de9e4147779697d566609778de","47aeba9b43d64d5e996a281a5b77eb3d","23ec3e7f115f416b9bcc280e4c1cc7ad","9ac016fa197b4502a70447510d6f901a","ed4b0bc9387e4599ac57d3760a6cff78","ce0515259bd0435f85b0156ec0f70c10","ee68887bab4b416f8af83c13689d7a10","031eab9705c148f9894f90ff8371ad54","1396db3318d54f558291d029e33ae1d0","b49fc0bf68f4421096a619e305372b7c","cc2944fefb3e483295632a89456637e3"]},"executionInfo":{"status":"ok","timestamp":1607055000791,"user_tz":300,"elapsed":22450,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"65c206d8-46c7-4539-98c8-3e546b1f3411"},"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","config = AutoConfig.from_pretrained('bert-base-uncased')\n","bert_model = AutoModel.from_config(config)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c2c8ee1234f4bdd8f09df75d61a91c4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b46c92262729468585d6f565936b90c6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ac016fa197b4502a70447510d6f901a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XcY-AENpsy2H"},"source":["TODO:\n","- Complete the forward function of the following class such that the model can do finetuning on RTE dataset.\n","- For more instructions, please refer to the hw5 pdf."]},{"cell_type":"code","metadata":{"id":"EwLCrHQiG6fz"},"source":["class SequenceClassificationBERT(nn.Module):\n","      \n","    def __init__(self, config, bert_model):\n","        super().__init__()\n","        self.config = config\n","        self.num_labels = config.num_labels\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","        self.bert = bert_model\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        # make sure that all the arguments in the forward() function is used\n","        # somewhere in the code\n","\n","        ##### \n","\n","        outputs = self.bert(input_ids=input_ids,\n","                            attention_mask=attention_mask,\n","                            token_type_ids=token_type_ids,\n","                            position_ids=position_ids,\n","                            head_mask=head_mask,\n","                            inputs_embeds=inputs_embeds,\n","                            output_attentions=output_attentions,\n","                            output_hidden_states=output_hidden_states,\n","                            return_dict=return_dict)\n","        \n","        pooler_output = outputs[1] #outputs['pooler_output']\n","        pooler_output = self.dropout(pooler_output)\n","        logits = self.classifier(pooler_output)\n","        \n","        loss = torch.nn.functional.cross_entropy(logits, labels)\n","\n","        #####\n","\n","        # do not change the lines below, so make sure your code works for the\n","        # lines below\n","        output = (logits,) + outputs[2:]\n","        return ((loss,) + output) if loss is not None else output\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ouMfVHXDsYx6"},"source":["model = SequenceClassificationBERT(config=config, bert_model=bert_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GrSMlKA29vz3"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"pw3Uy5Bvrwk0"},"source":["TODO:\n","- Print out the number of trainable parameters in the BERT model. This can be done in one line. Please feel free to look up resources online. We also briefly touched upon relevant materials in Lab 3, but here, make sure you only count the number of trainable parameters."]},{"cell_type":"code","metadata":{"id":"XELONlQrrtm0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607055000794,"user_tz":300,"elapsed":18543,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"ed6411f3-91f6-41ca-fbca-20da6fc46e71"},"source":[" n_parameters = sum([param.numel() for param in bert_model.parameters() if param.requires_grad])\n"," print(n_parameters)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["109482240\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RHiacH7Hvnjx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607055002549,"user_tz":300,"elapsed":19115,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"bed38caa-60ef-4bea-b4df-7f4ca3fc8177"},"source":["train_dataset = GlueDataset(data_args, tokenizer=tokenizer)\n","eval_dataset = GlueDataset(data_args, tokenizer=tokenizer, mode=\"dev\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/datasets/glue.py:77: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:521: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"gp6x_cKhsBJV"},"source":["Now we train the model. Please make sure to read the pdf instructions. When you report results in the pdf writeup, make sure you report the mean and std of >=3 runs with different random seeds. Consider using ```set_seed(some number)``` before the below cell, before each run.\n","\n","Make sure in each run, you're picking the best validation accuracy. We're using Trainer instead of the normal training loop which we have seen many many times earlier in the semester. In the trainer, we need to specify ```num_train_epochs``` (in ```training_args```) which we defined above. Please feel free to modify ```training_args``` such that:\n","- The learning rate is small (around 0.00001).\n","- Your model doesn't have large improments on validation accuracy anymore, at the end of training. The expected behavior is that the final validation accuracy won't be much better than chance.\n","\n","We provided part of an example log below, but you may be able to get better accuracy. Again, make sure this run corresponds to using an non-pretrained BERT."]},{"cell_type":"markdown","metadata":{"id":"8EsG17YWRV5y"},"source":["###### seed=42"]},{"cell_type":"code","metadata":{"id":"W3Fm8zLfHIMo","colab":{"base_uri":"https://localhost:8080/","height":731},"executionInfo":{"status":"ok","timestamp":1606838401989,"user_tz":300,"elapsed":308095,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"da4715ba-ec4d-45d4-c4d9-f112d1f5031b"},"source":["# seed = 42\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 04:56, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.726530</td>\n","      <td>0.697098</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.709291</td>\n","      <td>0.695456</td>\n","      <td>0.487365</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.696165</td>\n","      <td>0.711550</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.701618</td>\n","      <td>0.696434</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.692432</td>\n","      <td>0.702387</td>\n","      <td>0.483755</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.679537</td>\n","      <td>0.708883</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.651396</td>\n","      <td>0.745231</td>\n","      <td>0.541516</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.583672</td>\n","      <td>0.962056</td>\n","      <td>0.483755</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.483394</td>\n","      <td>1.050688</td>\n","      <td>0.530686</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.461441</td>\n","      <td>1.023973</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.394179</td>\n","      <td>1.069573</td>\n","      <td>0.505415</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.382231</td>\n","      <td>1.127881</td>\n","      <td>0.530686</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.335760</td>\n","      <td>1.174829</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.352073</td>\n","      <td>1.220813</td>\n","      <td>0.505415</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.288638</td>\n","      <td>1.221541</td>\n","      <td>0.519856</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0, 'eval_acc': 0.51985559566787, 'eval_loss': 1.2215412855148315}"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":976},"id":"vU9PrVSYUPdX","executionInfo":{"status":"ok","timestamp":1606843478901,"user_tz":300,"elapsed":308523,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"4907ab23-375f-4e0b-9d80-0d34a3adbd55"},"source":["# seed = 42\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 05:01, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.726530</td>\n","      <td>0.691287</td>\n","      <td>0.523466</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.700166</td>\n","      <td>0.689972</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.709291</td>\n","      <td>0.693458</td>\n","      <td>0.530686</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.692685</td>\n","      <td>0.694180</td>\n","      <td>0.534296</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.698886</td>\n","      <td>0.698426</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.689901</td>\n","      <td>0.696577</td>\n","      <td>0.501805</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.681027</td>\n","      <td>0.704986</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.678059</td>\n","      <td>0.710867</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.663324</td>\n","      <td>0.746819</td>\n","      <td>0.509025</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.638553</td>\n","      <td>0.920932</td>\n","      <td>0.480144</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.612691</td>\n","      <td>0.779223</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.592833</td>\n","      <td>0.883023</td>\n","      <td>0.559567</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.500065</td>\n","      <td>0.940270</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.495794</td>\n","      <td>0.982269</td>\n","      <td>0.530686</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.447440</td>\n","      <td>1.034129</td>\n","      <td>0.563177</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.451779</td>\n","      <td>1.014471</td>\n","      <td>0.534296</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.393250</td>\n","      <td>1.108277</td>\n","      <td>0.534296</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.384637</td>\n","      <td>1.175769</td>\n","      <td>0.523466</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.338046</td>\n","      <td>1.194011</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.339560</td>\n","      <td>1.227353</td>\n","      <td>0.523466</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.322102</td>\n","      <td>1.254583</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.314577</td>\n","      <td>1.305118</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.292347</td>\n","      <td>1.295611</td>\n","      <td>0.512635</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0, 'eval_acc': 0.516245487364621, 'eval_loss': 1.2973672151565552}"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"niCRjZF3RSOK"},"source":["###### seed=66"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":765},"id":"-xlzi7QMDdpi","executionInfo":{"status":"ok","timestamp":1606840611756,"user_tz":300,"elapsed":300176,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"a4f36045-13e3-4155-cdd1-5ff7e3ba2ab0"},"source":["# seed = 66\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 04:58, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.727851</td>\n","      <td>0.703836</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.708654</td>\n","      <td>0.696329</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.697048</td>\n","      <td>0.708082</td>\n","      <td>0.523466</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.705909</td>\n","      <td>0.696599</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.698485</td>\n","      <td>0.704714</td>\n","      <td>0.462094</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.690310</td>\n","      <td>0.705285</td>\n","      <td>0.480144</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.669762</td>\n","      <td>0.893986</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.625031</td>\n","      <td>0.885702</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.509842</td>\n","      <td>0.961451</td>\n","      <td>0.541516</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.537305</td>\n","      <td>1.010956</td>\n","      <td>0.480144</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.414495</td>\n","      <td>1.212628</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.473114</td>\n","      <td>1.163776</td>\n","      <td>0.512635</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.374367</td>\n","      <td>1.190242</td>\n","      <td>0.509025</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.372311</td>\n","      <td>1.217106</td>\n","      <td>0.534296</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.314511</td>\n","      <td>1.232878</td>\n","      <td>0.530686</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.5306859205776173,\n"," 'eval_loss': 1.2328784465789795}"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":976},"id":"5KvqnRI2Rt1I","executionInfo":{"status":"ok","timestamp":1606842863292,"user_tz":300,"elapsed":307941,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"a849dcaa-cbf1-4503-e6e1-4429fe497112"},"source":["# seed = 66\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 05:01, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.727851</td>\n","      <td>0.690940</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.699387</td>\n","      <td>0.691400</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.708654</td>\n","      <td>0.696796</td>\n","      <td>0.480144</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.696052</td>\n","      <td>0.692157</td>\n","      <td>0.541516</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.705842</td>\n","      <td>0.700376</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.693251</td>\n","      <td>0.696420</td>\n","      <td>0.501805</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.683660</td>\n","      <td>0.696539</td>\n","      <td>0.545126</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.701664</td>\n","      <td>0.719854</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.694876</td>\n","      <td>0.739392</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.665021</td>\n","      <td>0.725499</td>\n","      <td>0.487365</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.643380</td>\n","      <td>0.848738</td>\n","      <td>0.480144</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.605618</td>\n","      <td>0.864405</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.614522</td>\n","      <td>0.820430</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.540708</td>\n","      <td>0.908226</td>\n","      <td>0.487365</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.475609</td>\n","      <td>1.094773</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.425644</td>\n","      <td>1.062715</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.442020</td>\n","      <td>1.071220</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.407678</td>\n","      <td>1.122792</td>\n","      <td>0.534296</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.397633</td>\n","      <td>1.200000</td>\n","      <td>0.458484</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.363624</td>\n","      <td>1.193010</td>\n","      <td>0.505415</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.351270</td>\n","      <td>1.201352</td>\n","      <td>0.501805</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.326066</td>\n","      <td>1.229510</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.313898</td>\n","      <td>1.232388</td>\n","      <td>0.516245</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0, 'eval_acc': 0.51985559566787, 'eval_loss': 1.2328428030014038}"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"0EiWLQ8RRC4V"},"source":["###### seed=1024"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":765},"id":"AmzVsxZ0DeZW","executionInfo":{"status":"ok","timestamp":1606840128062,"user_tz":300,"elapsed":299821,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"4bc8745d-8eaf-4307-b0fa-d01439a43dfc"},"source":["# seed = 1024\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 04:57, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.736307</td>\n","      <td>0.697712</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.707634</td>\n","      <td>0.694633</td>\n","      <td>0.509025</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.694101</td>\n","      <td>0.709252</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.705873</td>\n","      <td>0.693536</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.691027</td>\n","      <td>0.702120</td>\n","      <td>0.480144</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.682469</td>\n","      <td>0.701830</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.650897</td>\n","      <td>0.761242</td>\n","      <td>0.537906</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.603193</td>\n","      <td>0.863979</td>\n","      <td>0.494585</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.467567</td>\n","      <td>0.974652</td>\n","      <td>0.505415</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.453784</td>\n","      <td>1.282012</td>\n","      <td>0.490975</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.455080</td>\n","      <td>1.105716</td>\n","      <td>0.505415</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.415453</td>\n","      <td>1.205031</td>\n","      <td>0.469314</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.386965</td>\n","      <td>1.244596</td>\n","      <td>0.462094</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.361935</td>\n","      <td>1.232435</td>\n","      <td>0.469314</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.323259</td>\n","      <td>1.243341</td>\n","      <td>0.465704</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.4657039711191336,\n"," 'eval_loss': 1.2433407306671143}"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"q3XS-GDEM0tB","executionInfo":{"status":"ok","timestamp":1606841529745,"user_tz":300,"elapsed":304361,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"1212ecfc-6582-45ac-d83a-67ece535096b"},"source":["# seed = 1024\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 05:02, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.736307</td>\n","      <td>0.690416</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.703807</td>\n","      <td>0.690547</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.707634</td>\n","      <td>0.691204</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.692734</td>\n","      <td>0.696762</td>\n","      <td>0.487365</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.706489</td>\n","      <td>0.695748</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.690385</td>\n","      <td>0.695951</td>\n","      <td>0.498195</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.684503</td>\n","      <td>0.698780</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.695887</td>\n","      <td>0.712947</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.676639</td>\n","      <td>0.708457</td>\n","      <td>0.552347</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.656378</td>\n","      <td>0.738680</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.634560</td>\n","      <td>0.735587</td>\n","      <td>0.512635</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.616604</td>\n","      <td>0.849645</td>\n","      <td>0.548736</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.600989</td>\n","      <td>0.794824</td>\n","      <td>0.563177</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.555469</td>\n","      <td>0.898895</td>\n","      <td>0.501805</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.491387</td>\n","      <td>0.969442</td>\n","      <td>0.487365</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.443706</td>\n","      <td>0.977939</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.451343</td>\n","      <td>1.012496</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.387191</td>\n","      <td>1.072776</td>\n","      <td>0.523466</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.400499</td>\n","      <td>1.071877</td>\n","      <td>0.501805</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.368809</td>\n","      <td>1.093116</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.349402</td>\n","      <td>1.117071</td>\n","      <td>0.505415</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.345802</td>\n","      <td>1.136014</td>\n","      <td>0.512635</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.338318</td>\n","      <td>1.146452</td>\n","      <td>0.498195</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.49458483754512633,\n"," 'eval_loss': 1.1478031873703003}"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"KWL5fqXdkkED"},"source":["### From pretrained BERT"]},{"cell_type":"markdown","metadata":{"id":"ej94TjTZzBTE"},"source":["Now, let's do the above experiments using a pretrained BERT!"]},{"cell_type":"markdown","metadata":{"id":"5XINTMIEyJQX"},"source":["TODO:\n","- Complete the following three lines such that ```tokenizer``` and ```config``` and ```bert_model``` corresponds to the ```model_name``` we defined in the above cells. \n","- IMPORTANT (different from the TODO a few cells above): make sure that the BERT model below loads the pretrained weights!"]},{"cell_type":"code","metadata":{"id":"No783Jh23S4K"},"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","config = AutoConfig.from_pretrained('bert-base-uncased')\n","bert_model = AutoModel.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xfLG6_Rp3TEE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606838414701,"user_tz":300,"elapsed":313681,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"f98ac34e-e259-4367-c2a0-b8d702226691"},"source":["bert_model "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"bfVkYRgm3TM4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607057369890,"user_tz":300,"elapsed":1191,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"0c7e71e0-62cb-42ec-8215-5b5fe54c08cf"},"source":["train_dataset = GlueDataset(data_args, tokenizer=tokenizer)\n","eval_dataset = GlueDataset(data_args, tokenizer=tokenizer, mode=\"dev\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/datasets/glue.py:77: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:521: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"TaSoTMr06n2-"},"source":["model = SequenceClassificationBERT(config=config, bert_model=bert_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FRcT8J4Fy1ii"},"source":["TODO:\n","- Similarly, we train the model. For more instructions, please see the TODO cells above (i.e., the TODO corresponding to training the model, when we're not loading weights into BERT), as well as the hw5 pdf."]},{"cell_type":"markdown","metadata":{"id":"WJ3hM1UzBJCS"},"source":["##### seed=42"]},{"cell_type":"code","metadata":{"id":"d20jbJV3GjOk","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1607055333280,"user_tz":300,"elapsed":330704,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"14693065-72f9-41cb-e3cc-2f6c60a6a163"},"source":["def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 05:04, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.702725</td>\n","      <td>0.667568</td>\n","      <td>0.624549</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.665358</td>\n","      <td>0.657738</td>\n","      <td>0.602888</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.591188</td>\n","      <td>0.651313</td>\n","      <td>0.606498</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.500107</td>\n","      <td>0.674072</td>\n","      <td>0.624549</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.454714</td>\n","      <td>0.716490</td>\n","      <td>0.613718</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.365586</td>\n","      <td>0.763500</td>\n","      <td>0.638989</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.306803</td>\n","      <td>0.788521</td>\n","      <td>0.635379</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.264215</td>\n","      <td>0.847433</td>\n","      <td>0.635379</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.205447</td>\n","      <td>0.897948</td>\n","      <td>0.631769</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.168385</td>\n","      <td>0.959609</td>\n","      <td>0.617329</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.164056</td>\n","      <td>0.992183</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.108636</td>\n","      <td>1.062991</td>\n","      <td>0.617329</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.108133</td>\n","      <td>1.068825</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.095062</td>\n","      <td>1.086898</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.071516</td>\n","      <td>1.131771</td>\n","      <td>0.653430</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.072449</td>\n","      <td>1.213809</td>\n","      <td>0.635379</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.066382</td>\n","      <td>1.253003</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.059573</td>\n","      <td>1.335351</td>\n","      <td>0.631769</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.048402</td>\n","      <td>1.394474</td>\n","      <td>0.635379</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.048156</td>\n","      <td>1.378486</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.053712</td>\n","      <td>1.396390</td>\n","      <td>0.649819</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.038066</td>\n","      <td>1.409737</td>\n","      <td>0.649819</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.044436</td>\n","      <td>1.412174</td>\n","      <td>0.649819</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.6498194945848376,\n"," 'eval_loss': 1.4110996723175049}"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"nqxkzC1CBMWq"},"source":["##### seed=66"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":981},"id":"WEbPzZiCBhZG","executionInfo":{"status":"ok","timestamp":1607056705014,"user_tz":300,"elapsed":311345,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"0af1bee8-e45f-44a9-c7c6-9026fbc7b575"},"source":["def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 05:03, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.712786</td>\n","      <td>0.689428</td>\n","      <td>0.545126</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.685640</td>\n","      <td>0.682427</td>\n","      <td>0.563177</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.639523</td>\n","      <td>0.638400</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.537166</td>\n","      <td>0.664761</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.498509</td>\n","      <td>0.681198</td>\n","      <td>0.635379</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.399030</td>\n","      <td>0.759685</td>\n","      <td>0.631769</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.323567</td>\n","      <td>0.760996</td>\n","      <td>0.660650</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.286551</td>\n","      <td>0.828829</td>\n","      <td>0.657040</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.208386</td>\n","      <td>0.924486</td>\n","      <td>0.620939</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.161066</td>\n","      <td>1.044224</td>\n","      <td>0.602888</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.136770</td>\n","      <td>1.092779</td>\n","      <td>0.617329</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.125538</td>\n","      <td>1.082364</td>\n","      <td>0.617329</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.107414</td>\n","      <td>1.105391</td>\n","      <td>0.657040</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.098095</td>\n","      <td>1.252751</td>\n","      <td>0.628159</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.077776</td>\n","      <td>1.371320</td>\n","      <td>0.613718</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.078353</td>\n","      <td>1.352070</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.055617</td>\n","      <td>1.414177</td>\n","      <td>0.635379</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.060561</td>\n","      <td>1.481477</td>\n","      <td>0.631769</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.041826</td>\n","      <td>1.500528</td>\n","      <td>0.635379</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.044748</td>\n","      <td>1.540141</td>\n","      <td>0.635379</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.052274</td>\n","      <td>1.573221</td>\n","      <td>0.638989</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.043622</td>\n","      <td>1.591686</td>\n","      <td>0.631769</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.034974</td>\n","      <td>1.580159</td>\n","      <td>0.635379</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0, 'eval_acc': 0.6353790613718412, 'eval_loss': 1.583669662475586}"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"3HpF9AvNBoue"},"source":["##### seed=1024"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"PHseTefaFZlZ","executionInfo":{"status":"ok","timestamp":1607057694425,"user_tz":300,"elapsed":311851,"user":{"displayName":"Lizhong Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjjyLw9V_KYj28s8Zns63WjSqKD8YDv0GhyiK1E4A=s64","userId":"10873032871679177977"}},"outputId":"3df11351-de5a-48d7-b5aa-e1174e9ab3df"},"source":["def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 05:04, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.704031</td>\n","      <td>0.693695</td>\n","      <td>0.476534</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.693677</td>\n","      <td>0.676955</td>\n","      <td>0.559567</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.659933</td>\n","      <td>0.655580</td>\n","      <td>0.599278</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.565732</td>\n","      <td>0.699989</td>\n","      <td>0.610108</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.526754</td>\n","      <td>0.669775</td>\n","      <td>0.617329</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.420376</td>\n","      <td>0.738756</td>\n","      <td>0.613718</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.327282</td>\n","      <td>0.842197</td>\n","      <td>0.617329</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.293008</td>\n","      <td>0.870432</td>\n","      <td>0.638989</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.223510</td>\n","      <td>0.965117</td>\n","      <td>0.620939</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.169800</td>\n","      <td>1.079856</td>\n","      <td>0.620939</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.158901</td>\n","      <td>1.172774</td>\n","      <td>0.617329</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.093107</td>\n","      <td>1.218889</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.112174</td>\n","      <td>1.271992</td>\n","      <td>0.620939</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.077581</td>\n","      <td>1.366638</td>\n","      <td>0.624549</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.067676</td>\n","      <td>1.460526</td>\n","      <td>0.606498</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.061260</td>\n","      <td>1.492796</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.042045</td>\n","      <td>1.550988</td>\n","      <td>0.631769</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.038945</td>\n","      <td>1.637083</td>\n","      <td>0.649819</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.034349</td>\n","      <td>1.710441</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.041959</td>\n","      <td>1.722896</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.034888</td>\n","      <td>1.761446</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.022515</td>\n","      <td>1.737183</td>\n","      <td>0.631769</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.028068</td>\n","      <td>1.763302</td>\n","      <td>0.624549</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.6245487364620939,\n"," 'eval_loss': 1.7666387557983398}"]},"metadata":{"tags":[]},"execution_count":8}]}]}